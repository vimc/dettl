---
title: "Using dettl for importing data"
author: "Robert Ashton"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{dettl}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
default_reporter <- testthat::default_reporter()
options(testthat.default_reporter = "summary")
```


Dettl provides a way to make data tidying and ingestion into a database easier, more testable and more robust. We do that by employing an ETL (extract, transform, load) like workflow to separate out different concerns of your data import and allow testing after each stage.

## ETL

ETL is a pattern for general copying of data from one or more sources to another destination which expects the data in a different form from the sources. It consists of three basic steps

**Extract** - Step is responsible for selecting and accessing any required data from relevant sources (local files or DB). The data is read into memory and can be verified by running a set of tests after step has completed.

**Transform** - Step is responsible for transforming the extracted data into a form ready for loading into the destination database. Expect this is where the bulk of the work will be done. The transformed data can be verifed by running a set of tests after the step has completed.

**Load** - Step is responsible for loading the transformed data into the destination database. A set of post-load tests can be defined which will be run after the data is loaded into the database. If any of the tests fail the DB update will roll back, otherwise changes are committed.

## File structure

To define an import a directory structure as follows is required

```
project_directory
|── import_1
|   |── dettl.yml
|── import_2
|   |── dettl.yml
|── other imports ...
|── dettl_config.yml
```

Configuration files are required at 2 levels

* `dettl_config.yml` - Configuration at the project level used to configure DB connection information for any database which you wish to import to for each import subdirectory. Note that you must specify the `log_table` for each database. This is the table which import runs will be logged to.

```yaml
db:
  test:
    driver: RSQLite::SQLite
    args:
      dbname: test.sqlite
    log_table: dettl_import_log
  uat:
    driver: RPostgres::Postgresql
    args:
      dbname: montagu
      host: https://example.com
      port: 12345
      user: example
      password: password
    log_table: dettl_import_log
```

* `dettl.yml` - Configuration at the individual import level used to say what functions should be used for each stage and what R files should be sourced. Also used to configure the test files required. 

Taking a closer look at the structure of an individual import directory we expect something like.
```
import_directory
|── dettl.yml
|   R
|   |── extract.R
|   |── transform.R
|   |── load.R
|── data
|   |── source_file_1.csv
|   |── source_file_2.csv
|   |── ...
|── tests
|   |── test_extract.R
|   |── test_transform.R
|   |── test_load.R
```
Which will then be tied together to form the import using the `dettl.yml` config file e.g.

```yaml
sources:
  - R/extract.R
  - R/transform.R
  - R/load.R

extract:
  func: extract
  test: R/test_extract.R

transform:
  func: transform
  test: R/test_transform.R

load:
  func: load
  test: R/test_load.R
```

The import at a minimum needs code to define 3 functions one for each stage of the extract, transform and load.

## Creating a new ETL import

If you want to create a new import within an existing project this can be done by opening the project as an RStudio project and using `dettl_new()`. Note that the use of `withr::with_dir(tempdir(), ...)` in the example below is because this is running in a vignette and the code is an example. This is not necessary when using `dettl` in a real environment.

```{r}
import_name <- withr::with_dir(tempdir(), 
  dettl::dettl_new("person_information")
)
```

This will create a new directory called `person_information` prepended with the current date containing the default `dettl.yml` config and 3 `R` files for you to fill in to the the extract, transform and load and 3 files for testing after each stage of the import.

If you want to create a new import within a new project then you will need to manually create a new RStudio project and create a `dettl_config.yml` file. You can then proceed as above.

## Developing the import

To develop a complete import you need to implement the extract, transform and load stages.

Open the created `R/extract.R` file and implement the templated `extract` function. This can delegate to other R functions written elsewhere. If you add any other R files they will need to be added to the list of `sources` in the `dettl.yml`. The extract code should just read data the required data into memory and do no more. For our simple example we want to read from a csv.

```r
extract <- function(path, con) {
  raw_data <- list()
  raw_data$people <- read.csv(file.path(path, "data/people.csv"), stringsAsFactors = FALSE)
  raw_data
}
```

You should also define some tests for this stage in the `R/test_extract.R` file. These are written using the [testthat package](http://r-pkgs.had.co.nz/tests.html). The extracted data is made available via the variable `extracted_data` which can be used from within the configured test file. An example test to check that our extract function has extracted 3 rows of data would be.

```r
context("extract")

testthat::test_that("extracted data contains 3 rows", {
  expect_equal(nrow(extracted_data$people), 3)
})
```

After completing the implementation of the extract stage you can run just that step to check that the extracted data looks as expected. Note that the directory must be under version control and up to date with remote to run the import. This check is skipped if running in `dry_run` mode. See [Running the import](#run) for more details about this. When creating a new import also pass the database which this import is for, this must match one of the databases configured in the `dettl_config.yml`. See example below for a previously configured example. Note that `import_path` is the path to an import directory with structure like above.


```{r include = FALSE}
path <- dettl:::prepare_test_import(
  system.file("examples", "person_information", package = "dettl"),
  system.file("examples", "dettl_config.yml", package = "dettl"))
import_path <- file.path(path, "person_information")
```

```{r}
import <- dettl::dettl(import_path, db_name = "test")
import$extract()
extracted_data <- import$get_extracted_data()
```
The extracted data can be inspected to ensure it looks as expected.
```{r}
print(extracted_data)
```

Secondly open the created `R/transform.R` file. Again you need to implement the templated `transform` function. Similarly to the extract stage this can delegate to other R functions if any files used are added to the `sources` block in the config. Similarly you should write some tests for the transformed data. Important to note is the form of the returned data should be as a named list of data frames. Where each list item represents a table from the database with name matching the name in the DB schema. And each column in the data frame should match an existing column in the database. After the transform step is run the user specified tests will be run automatically, in addition to these we test that the returned data conforms to the DB schema and fail if it does not do so. For example for our simple people example our transform code could be something like

```r
transform <- function(extracted_data) {
  transformed_data <- list()
  transformed_data$people <- extracted_data$people[which(extracted_data$people$age < 50), ]
  transformed_data
}
```

and our user defined test

```r
context("transform")

testthat::test_that("transformed data contains 2 rows", {
  expect_equal(nrow(transformed_data$people), 2)
})
```

Like with developing the extract stage you can now run the import up the transform step to check it is working though you should try to add any checks required for accepting the transform stage to the test file.

```{r}
import$transform()
transformed_data <- import$get_transformed_data()
```

The transformed data can be inspected to ensure it looks as expected.
```{r}
print(transformed_data)
```

The final stage to implement is the load stage. Note that you can use a default implementation for the load stage. This will append the `transformed_data` to existing tables in the database respecting any foreign key constraints configured via the `dettl.yml`. See section below for details about [default load](#default_load). To implement this open the `R/load.R` file. An automatically generated implementation will already be there for you, this simply takes each data frame in the transformed data list and appends those rows to the relevant table in the database. If something more complicated is required this can be replaced. Expect that this stage is only really a set of update queries to be run on the database implemented in R.

The important implementation for this stage is the testing. The load stage will be run in a transaction then the tests will be run. If any of the tests fail the transaction will be rolled back, otherwise it will be committed. You can write two types of test here, the first simplest is using the active connection to the database to query the loaded data and test the output. For example

```r
context("load")

testthat::test_that("people has 2 rows 2", {
  expect_equal(DBI::dbGetQuery(con, "SELECT count(*) from people")[1,1], 2)
})
```

These type of tests can only be used to look at the DB after the load has been done. You can also define tests which can test for changes in the DB between before and after the load has run. These require 2 steps.

First you need to define a function to query the database to get data you're interested in. e.g.

```r
test_queries <- function(con) {
  values <- list()
  values$count <-  DBI::dbGetQuery(con, "SELECT count(*) from people")[1,1]
  values
}
```

This should write the data into a list with meaningful names as these names will be used in the test. You need to then define the function used in the `dettl.yml` config in the `load` block using the following,

```yaml
load:
  func: load
  verification_queries: test_queries
  test: R/test_load.R
```
Making sure any additional R files have been added to the `sources` block. The `verification_queries` will be then run before and after the DB update has been run and the output made available to the tests as lists `before` and `after` so differences can be tested e.g.

```r
context("load")

testthat::test_that("No of rows in people increases by 2", {
  expect_equal(after$count, before$count + 2)
})
```

After this stage has been implemeneted the import can be run end-to-end.

## Running the import {#run}

The import can be run by first creating a new import object using the name of the directory containing the import you want to run. Again note that the `import_path` here is the path to import directory.

```{r include = FALSE}
path <- dettl:::prepare_test_import(
  system.file("examples", "person_information", package = "dettl"),
  system.file("examples", "dettl_config.yml", package = "dettl"))
import_path <- file.path(path, "person_information")
```

```{r}
import <- dettl::dettl(import_path, db_name = "test")
```

You can then run the import by running

```{r}
import$extract()
import$transform()
import$load()
```

This will fail if any of the stages fail. 

Alternatively you can run the import up to just a specific point to view the output if desired - which should be useful for debugging any import problems e.g.

```{r include = FALSE}
## Get a clean DB for running import a second time
path <- dettl:::prepare_test_import(
  system.file("examples", "person_information", package = "dettl"),
  system.file("examples", "dettl_config.yml", package = "dettl"))
import_path <- file.path(path, "person_information")
import <- dettl::dettl(import_path, db_name = "test")
```
```{r}
import$extract()
import$transform()
```

Will run just the `extract` and `transform` stages of the import. Note that when any stage is run we automatically run any of the tests associated with that stage which have been configured. You can use the import object to view the extracted or transformed data.

```{r}
extracted_data <- import$get_extracted_data()
transformed_data <- import$get_transformed_data()
```

The load stage can then be run separately

```{r}
import$load()
```

We can then inspect the database to see that the data has indeed been loaded
```{r}
con <- import$get_connection()
DBI::dbGetQuery(con, "SELECT * FROM people")
```

The import can be run in `dry_run` which will be useful for development. 

```{r include = FALSE}
## Get a clean DB for running dry run import
path <- dettl:::prepare_test_import(
  system.file("examples", "person_information", package = "dettl"),
  system.file("examples", "dettl_config.yml", package = "dettl"))
import_path <- file.path(path, "person_information")
import <- dettl::dettl(import_path, db_name = "test")
```
```{r}
import$extract()
import$transform()
import$load(dry_run = TRUE)
```

This will rollback any changes which have been made to the database before the connection is closed. Note that it also skips the check that the git repository is up to date with remote and so should be used when developing the import.

```{r echo = FALSE, results = "hide"}
## Reset default reporter.
options(testthat.default_reporter = default_reporter)
```

## Default load stage {#default_load}

`dettl` has a default implementation for the load stage of the import. At its most simple this will just take the named list of `transformed_data` and append each of these data frames to the table in the database with matching name. To use the default load step requires defining that the default load should be used in the load block of `dettl.yml` e.g.

```yml
load:
  default: TRUE
  verification_queries: test_queries
  test: R/test_load.R
```

Using a default load means that the configured `sources` in the `dettl.yml` no longer need to define a `load` function. A file containing tests for the load stage is still required.

The default load can also load data resepecting primary key constraints configured via `dettl.yml`. For example if we want to load data where we have `transformed_data` taking the form

```{r echo = FALSE}
people <- data.frame(c(1,2),
                     c("Alice", "Bob"),
                     c(25, 45),
                     c(175, 187),
                     stringsAsFactors = FALSE)
colnames(people) <- c("id", "name", "age", "height")
jobs <- data.frame(c(1, 2),
                   c("researcher", "developer"),
                   stringsAsFactors = FALSE)
colnames(jobs) <- c("person", "job")
knitr::kable(people, caption = "people")
knitr::kable(jobs, caption = "jobs")
```

where `id` is the primary key of table `people` which is used as a foreign key for the `person` column of table `jobs`. In the transformed data these ids are just temporary values used to associate the new rows of data with each other. The tables themselves may already have entries with these primary keys used so when the default load is run the primary keys are updated when a new record is added. 

We need to configure in the `dettl.yml` which fields in which tables are primary keys and where they are used as foreign keys. For the example data above this is done as follows

```yaml
rewrite_keys:
  people:
    primary: id
    foreign:
      jobs: person
```

This tells `dettl` that the primary key `id` of the table `people` is used as a foreign key in the `jobs` table as field `person`. This means when the import is run, the `people` table will be appended to and the new primary keys for the added rows retrieved. These ids will then be updated from the old ones to the new ones in every usage as a foreign key meaning when the `jobs` table is appended to the ids will refer to the correct `people`.
